dqn_example.py - - - contains the RF code. It is set up to just run from the get go.  Alot of the code came from 
https://markelsanz14.medium.com/introduction-to-reinforcement-learning-part-1-multi-armed-bandit-problem-618e8cbf9d4b
https://markelsanz14.medium.com/introduction-to-reinforcement-learning-part-2-q-learning-4d93f9f37e3e 
https://markelsanz14.medium.com/introduction-to-reinforcement-learning-part-3-q-learning-with-neural-networks-algorithm-dqn-1e22ee928ecd
but a modified a bit to get it to work (the code fro the ink didn't work as well for me. I think this points to a brittle nature of DQN 
rather than the og code) dqn_example.weights.h5 has the concurrent saved weights. If you don't want to love these weights and start 
from scratch, comment out main_nn.load_weights('cnn_keras_example_.weights.h5') and target_nn.load_weights('cnn_keras_example_.weights.h5') 
and set epsiolon to .5

grid world is a very basic example of the Q-learning algorithm. I would say it's worth starting there if you are just getting into this.
multi-armed-bandid.py is an intermediate level Q-learning examaple. Also recommend looking through it.

racetrack_learning.py  is the project in progress which I want to get working! 


/literature contains some of the papers which may help with understanding the algorithms in this repo


Here are a few useful links
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
libraries: 
https://www.gymlibrary.dev/content/basic_usage/
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
RL help: 
https://www.turing.com/kb/reinforcement-learning-algorithms-types-examples
https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da 
